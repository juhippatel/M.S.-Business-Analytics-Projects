{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "MIS 382N: ADVANCED MACHINE LEARNING\n",
        "\n",
        "Assignment 4\n",
        "\n",
        "Total points: 75 + 5 bonus points\n",
        "\n",
        "Due: Monday, November 2 to be submitted via Canvas by 11:59 pm\n",
        "\n",
        "Your homework should be written in a python notebook. If you prefer, you can work in groups of two. **Please note that only one student per team needs to submit the assignment on Canvas but make sure to include both students' names and UT EIDs.**\n",
        "\n",
        "For any question that requires a handwritten solution, you may upload scanned images of your solution in the notebook or attach them to the assignment . You may write your solution using markdown as well.\n",
        "\n",
        "Please make sure your code runs and the graphs and figures are displayed in your notebook before submitting. (%matplotlib inline)\n",
        "\n",
        "**Additionally, upload any images you plan to incorporate in your notebook as attachments so we can see them in case the uploaded images don't appear properly on our end.**"
      ],
      "metadata": {
        "id": "npoWrtHxW8A-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This can be an individual assignment or group of 2. If you choose to do it as a group, please specify who you are working with (name and EID), then only one student should submit the homework. Put your name and eid here.**\n",
        "\n",
        "Name:\n",
        "\n",
        "EID:\n",
        "\n",
        "Name:\n",
        "\n",
        "EID:"
      ],
      "metadata": {
        "id": "FPr7qTDfW9C5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 1: Expected Loss Minimization [10 pts]\n",
        "Consider a binary classification problem with the following loss matrix -\n",
        "$$\n",
        "   {\\begin{array}{ccccc}\n",
        "   & & \\text{Predicted class} & \\text{           } &\\\\\n",
        "   & & C1 & C2 & Reject\\\\\n",
        "   \\text{True class} & C1 & 0 & r & c  \\\\\n",
        "   & C2 & s & 0 & c \\\\\n",
        "  \\end{array} } \n",
        "$$\n",
        "\n",
        "where the cost of rejection is a constant, and the costs $r$ and $s$ are positive real numbers. Let $f(x)=P(C1|x)$.\n",
        "\n",
        "\n",
        "**(a) [2.5 points]** Show that the expected loss when $x$ is labelled as $C_1$ is a decreasing function of $f(x)$ while expected loss when $x$ is labelled as $C_2$ is a increasing function of $f(x)$.  \n",
        "\n",
        "**(b) [2.5 points]** For $c=0$, show that the decision which minimizes the expected loss is to reject all instances of $x$\n",
        "\n",
        "**(c) [2.5 points]** Let $r=5$ and $s=2$, what is the minimum value of $c$ such that no instance of $x$ gets rejected (irrespective of  $f(x)$)?\n",
        "\n",
        "**(d) [2.5 points]** Let $r=7$, $s=4$, and $c=3$. Determine the  ranges of $f(x)$ for which the optimal decision is C1, reject and C2 respectively."
      ],
      "metadata": {
        "id": "3kF5773owvfR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 2: Logistic Regression [5 points]\n",
        "Consider the problem of predicting the success of students in their undergraduate degrees given their high school GPA and SAT scores. We have the variables $X_1 =$ high school GPA, $X_2$ = SAT score and Y = completing the undergraduate degree (binary). We then fit a logistic regression which produces coefficients, $β_0 = −7$, $β_1 = 2$, $β_2 = 0.001$ Estimate the probability that George who\n",
        "has a GPA of 3.4 and an SAT score of 1500 will complete his undergraduate degree successfully according to this model. By how much will the probability increase if the GPA increases to 3.7, with other factors remaining the same?"
      ],
      "metadata": {
        "id": "WyR-XDUVBE0N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Question 2: Classification and Handling Class Imbalance [35 points + 5 bonus points]"
      ],
      "metadata": {
        "id": "vwiBPkGX2vh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Only use this code block if you are using Google Colab.\n",
        "# If you are using Jupyter Notebook, please ignore this code block. You can directly upload the file to your Jupyter Notebook file systems.\n",
        "from google.colab import files\n",
        "\n",
        "## It will prompt you to select a local file. Click on “Choose Files” then select and upload the file. \n",
        "## Wait for the file to be 100% uploaded. You should see the name of the file once Colab has uploaded it.\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "MWJwIH6O24LF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 39
        },
        "outputId": "a9374e89-99e7-4d9f-d45e-7f917fb5ca6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-27dca5ed-a377-4b7a-a9fa-9aede3fb235d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-27dca5ed-a377-4b7a-a9fa-9aede3fb235d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "df = pd.read_csv('customer_churn_telcom.csv')"
      ],
      "metadata": {
        "id": "ETRfOnVf3Hge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing the first five rows\n",
        "df.head()"
      ],
      "metadata": {
        "id": "iJrt4H-C3PwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_unique_col_values(df):\n",
        "       for column in df:\n",
        "            if df[column].dtypes=='object':\n",
        "                print(f'{column}: {df[column].unique()}') \n",
        "\n",
        "print_unique_col_values(df)"
      ],
      "metadata": {
        "id": "Titxns6c3YPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [5 points] Data Preprocessing \n",
        "\n",
        "(a) [1 pt] Some of the columns have values like - no internet service or no phone service. Replace these two values with with a simple No"
      ],
      "metadata": {
        "id": "G6s0cK3G4NdW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace values with No\n"
      ],
      "metadata": {
        "id": "vR3lyeovaW7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(b) [1 pt] Convert all 'Yes' values to 1 and 'No' values to 0 <br>\n",
        "(c) [1 pt] Convert all  'Female' values to 1 and 'Male' values to 0"
      ],
      "metadata": {
        "id": "kndExGVU42kx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Changing values to 0/1\n",
        "\n",
        "yes_no_columns = ['Partner','Dependents','PhoneService','MultipleLines','OnlineSecurity','OnlineBackup',\n",
        "                  'DeviceProtection','TechSupport','StreamingTV','StreamingMovies','PaperlessBilling','Churn']"
      ],
      "metadata": {
        "id": "A_RQG50KaYPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(d) [2 pts] Perform one-hot encoding on the folowing columns: 'InternetService', 'Contract', 'PaymentMethod'"
      ],
      "metadata": {
        "id": "Tp2Tumrm6EVo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# One hot encoding for categorical columns\n",
        "# Name your final dataframe df 2\n",
        "\n",
        "# Your code here\n",
        "\n",
        "df2 = "
      ],
      "metadata": {
        "id": "4GeDoW_Za0fz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling\n",
        "cols_to_scale = ['tenure','MonthlyCharges','TotalCharges']\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "df2[cols_to_scale] = scaler.fit_transform(df2[cols_to_scale])"
      ],
      "metadata": {
        "id": "HgDAFheB56xz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "e) [1 pt] Split the dataset into training and test using a 80-20 split with a random state of 15. Perform stratified sampling on the target variable while doing so. Split the training data further into training (80%) and validation sets (20%) with a random state of 15. Perform stratified sampling on the target variable while doing so.\n",
        "\n",
        "Note: The 'stratify' parameter can be used for this in the train_test_split function. "
      ],
      "metadata": {
        "id": "aFnDhUR26pU2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train test split\n"
      ],
      "metadata": {
        "id": "tLz3bC3m6dkM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# With samples corresponding to the positive class being very low, we can clearly see the imbalance in our data \n",
        "print('Churn occurences in the training set \\n', y_train.value_counts())\n",
        "print('\\n')\n",
        "print('Churn occurences throughout the data \\n', y.value_counts())"
      ],
      "metadata": {
        "id": "2KuUiJVq7VhD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZJrYJVxT7-1d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [15 points] Decision Trees, Logistic Regression, and MLP\n",
        "\n",
        "Use the example provided [here](https://scikit-learn.org/stable/modules/tree.html) to get an idea of how to use sklearn's decision tree classifier.\n",
        "\n",
        "Go through the documentation [here](https://scikit-learn.org/0.16/modules/generated/sklearn.linear_model.LogisticRegression.html) to understand how to use sklearn's logistic regression model.\n",
        "\n",
        "Go through the documentation [here](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html) to understand how to use sklearn's MLP Model."
      ],
      "metadata": {
        "id": "kjAYHG1QK6TI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(a) [5 pts (+5 bonus points)] Train the three classifiers on the dataset and print confusion matrix on both - the validation data as well as the test data for all the three models (you can either use default parameters for MLP classifier or change them to obtain higher performance for additional bonus of 5 points). <br>\n",
        "(b) [5 pts] Plot the ROC Curves for all the three classifiers in a single graph and display the AUC-ROC scores for all the classifiers in this plot as well. Use both the validation and the test data to plot these curves as well as to calculate the AUC-ROC scores. Use one graph for validation data and one graph for test data (all models for validation data in one graph and all models for test data in one graph - and use this scheme for plotting in all subsequent plotting questions). <br>\n",
        "(c) [5 pts] Plot the Precision-Recall curves for all the three classifiers in a single graph. Use both the validation and the test data to plot these curves. Use one graph for validation data and one graph for test data.\n",
        "\n",
        "Helpful resources can be found here - \n",
        "1. [sklearn.tree.DecisionTreeClassifier.score](https://github.com/scikit-learn/scikit-learn/blob/37ac6788c/sklearn/base.py#L625)\n",
        "2.  [sklearn.linear_model.LogisticRegression.score](https://github.com/scikit-learn/scikit-learn/blob/37ac6788c/sklearn/base.py#L625)\n",
        "3. [sklearn.neutral_network.MLPClassifier.score](https://github.com/scikit-learn/scikit-learn/blob/36958fb24/sklearn/base.py#L640)\n",
        "4. [sklearn.metrics.plot_roc_curve](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.plot_roc_curve.html)\n",
        "5. [sklearn.metrics_confusion_matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)\n",
        "\n",
        "Note: In this question, we are using the default parameters for MLP classifier, but you can change these parameters to obtain higher accuracies. **For a bonus of 5 points, experiment with these parameters to obtain a higher performance (in terms of accuracy and AUC-ROC scores).**"
      ],
      "metadata": {
        "id": "-iheftYk8TOj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Decision Tree Classifier\n",
        "from sklearn import tree\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Answer here"
      ],
      "metadata": {
        "id": "sHZzMovL7a_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# Answer here"
      ],
      "metadata": {
        "id": "vY-24CyV-fqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP Classifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "# Answer here\n"
      ],
      "metadata": {
        "id": "z6jXS15--y2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot ROC curves"
      ],
      "metadata": {
        "id": "o19xktKgbx_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot PR curves"
      ],
      "metadata": {
        "id": "xWDR41UgbyHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [4 points] Handling Class Imbalance with SMOTE\n",
        "\n",
        "Go through the documentation [here](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html) to understand how to use imbalanced-learn's SMOTE to counter class imbalance in the data."
      ],
      "metadata": {
        "id": "1hte01p1BNSF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(a) [1 pt] Split the data into training (80%) and test sets (20%) with a random state of 15. Perform stratified sampling on the target variable while doing so.\n",
        "\n",
        "Note: The 'stratify' parameter can be used for this in the train_test_split function. "
      ],
      "metadata": {
        "id": "DDGPAvYrLLJs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df2.drop('Churn',axis='columns')\n",
        "y = df2['Churn']\n",
        "\n",
        "# Train test split"
      ],
      "metadata": {
        "id": "Icmp3EJ0LOwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(b) [2 pts] Perform SMOTE on the training data and print the value counts of the target variable in the data."
      ],
      "metadata": {
        "id": "rZFToY0eDEjZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To install imbalanced-learn library use pip install imbalanced-learn command\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Answer here"
      ],
      "metadata": {
        "id": "iLbZSI_o-27a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(c) [1 pt] Split the updated training data (on which SMOTE has been run) further into training (80%) and validation sets (20%) with a random state of 15. Perform stratified sampling on the target variable while doing so.\n",
        "\n",
        "Note: The 'stratify' parameter can be used for this in the train_test_split function. "
      ],
      "metadata": {
        "id": "bBmI59gEDh3Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Answer here"
      ],
      "metadata": {
        "id": "kpdlvaL3B8SM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of classes in training Data\n",
        "train_y.value_counts()"
      ],
      "metadata": {
        "id": "ZNb9xnW5B-lE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of classes in validation Data\n",
        "validation_y.value_counts()"
      ],
      "metadata": {
        "id": "folkBsCgLvn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [2 points] Retraining the Classifiers\n",
        "\n",
        "Now that we have created synthetic samples of the minority class, let's proceed further to see if we see any improvements in our results. For the two models - Logistic regressor and MLP, do the folowing:\n",
        "\n",
        "(a) [1 pt] Train a model on the training dataset. <br>\n",
        "(b) [1 pt] Make predictions on the test data using the trained model and print confusion matrix for both - the validation and the test data."
      ],
      "metadata": {
        "id": "RikiMZSkEs7q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression"
      ],
      "metadata": {
        "id": "7N09MtZqcTnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP"
      ],
      "metadata": {
        "id": "CfMceRxncTvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [9 points] Plotting and Comparison\n",
        "a) [1 pt] For the two classifiers (Logistic regression and MLP) - plot the ROC Curves in a single graph, display the AUC-ROC scores in this plot as well on both the validation and the test data. Use one graph for validation data and one graph for test data. <br>\n",
        "b) [1 pt] Plot the Precision-Recall curves for the two classifiers in a single graph on both the validation and the test data. Use one graph for validation data and one graph for test data. <br>\n",
        "c) [7 pts] Compare and contrast the performance of the classifiers with reference to these two plots and with reference to the plots that were computed before using SMOTE. Specifically comment on what you observed regarding the difference in performance on the validation vs. the test dataset, which is a better representative of the actual/original problem."
      ],
      "metadata": {
        "id": "yM5Y41h9D3b8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot ROC curves"
      ],
      "metadata": {
        "id": "S9qTDuMUccPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot PR curves"
      ],
      "metadata": {
        "id": "iQawBQAyccVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "c)"
      ],
      "metadata": {
        "id": "m7nFGprQccdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 4: Bayesian Belief Networks [15 pts]\n",
        "\n"
      ],
      "metadata": {
        "id": "AmLndaMeDwrb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Refer to the Bayesian Network Belief image (uploaded with the notebook on canvas) for this question. "
      ],
      "metadata": {
        "id": "LltKbWoIhdfz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "All nodes are binary and can take 0/1 values\n",
        "\n",
        "The probabilities are given below:\n",
        "\n",
        "P(Season = 1) = .001   \n",
        "P(Atmospheric Pressure = 1) = .0.002\n",
        "\n",
        "\n",
        "P(Rain = 1 | Season = 0, Atmospheric Pressure = 0) = .001  \n",
        "P(Rain = 1 | Season = 0, Atmospheric Pressure = 1) = .29  \n",
        "P(Rain = 1 | Season = 1, Atmospheric Pressure = 0) = .94  \n",
        "P(Rain = 1 | Season = 1, Atmospheric Pressure = 1) = .95\n",
        "\n",
        "P(Umbrella = 1 | Rain = 1) = .9  \n",
        "P(Umbrella = 1 | Rain = 0) = .05\n",
        "\n",
        "For the given Bayesian network, Compute the following probabilities : \n",
        "\n",
        "\n",
        "**(a) [4 pts]** Find the probability that  Umbrella = 0 \n",
        "\n",
        "**(b) [4 pts]** Given that there is low Atmospheric Pressure (Atmospheric Pressure = 0), what is the probability that Rain = 1\n",
        "\n",
        "**(c) [7 pts]** Given that it rains(Rain = 1), what is the probability that the it is rainy season (Season = 1)"
      ],
      "metadata": {
        "id": "6WX3FxClD-n7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 5: Support Vector Machines [10 pts]\n",
        "\n",
        "1. [3 pts] Explain in what sense the Support Vector Machine seeks an optimal answer in the space of linear classifiers.\n",
        "2. [3 pts] Describe how a slack variable works.\n",
        "3. [4 pts] Explain how the SVM framework can be extended in order to provide non-linear decision boundaries."
      ],
      "metadata": {
        "id": "FERAf2_RAQwS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sRvnprYqU92B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}